{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to add how many repetitive rounds...enter number of repetitions\n",
    "round=1\n",
    "repetitions = 10\n",
    "while round < repetitions + 1:\n",
    "    round += 1\n",
    "    if __name__ == '__main__':\n",
    "        env = gym.make('2048-v0')\n",
    "\n",
    "        #model hyperparameters (commetn what doesn need to be rewritten)\n",
    "        #ALPHA = 0.1\n",
    "        GAMMA = 0.99\n",
    "        #As already some knowledge, less randomness. still decreasing. reduce start             with each repetition\n",
    "        EPSILON = 1/round\n",
    "        #this variable counts how many times we have won.\n",
    "        won = 0\n",
    "        #value we want to reach due to memory restrictions.\n",
    "        #GOAL = 512\n",
    "        max_value = 0\n",
    "        #num_won = []\n",
    "        #max_values = []\n",
    "        #avg_values = []\n",
    "        max_total = 0\n",
    "\n",
    "        #construct state space\n",
    "    \n",
    "        #states = []\n",
    "        #Q = {}\n",
    "\n",
    "        #numGames = 5000\n",
    "        BATCH_SIZE = int(numGames/100)\n",
    "        \n",
    "        for i in range(numGames):\n",
    "            game_won = False\n",
    "            observation = numpy_transformer_light(env.reset())\n",
    "            s = tuple(observation)\n",
    "            #check if observation isn't already in states\n",
    "            if observation not in states:\n",
    "                states.append(observation)\n",
    "                for a in range(4):\n",
    "                    #we changed the state to a to avoid a TypeError,\n",
    "                    #because lists aren't hashable.S\n",
    "                    Q[tuple(s),a] = 0\n",
    "            rand = np.random.random()\n",
    "\n",
    "            done = False\n",
    "            epRewards = 0\n",
    "            while not done:      \n",
    "                # choice and validity check to avoid dead ends (loops)\n",
    "                a, observation_, reward, done = choseandcheck(Q, a, observation, EPSILON, env, s)\n",
    "\n",
    "                s_ = tuple(observation_)\n",
    "                if observation_ not in states:\n",
    "                    states.append(observation_)\n",
    "                    for a in range(4):\n",
    "                        #we changed the state to a to avoid a TypeError,\n",
    "                        #because lists aren't hashable.\n",
    "                        Q[tuple(s_),a] = 0\n",
    "                        \n",
    "\n",
    "                rand = np.random.random()\n",
    "                if rand < (1-EPSILON):\n",
    "                    a_ = maxAction(Q,s_)\n",
    "                else: \n",
    "                    a_ = np.random.randint(0,4)\n",
    "                epRewards += reward\n",
    "                Q[s,a] = Q[s,a] + ALPHA*(reward + GAMMA*Q[s_,a_] - Q[s,a])\n",
    "                \n",
    "                # no more needed. that does not check for validity of move. we incorporated thi in choseandcheck\n",
    "                # s,a = s_,a_\n",
    "\n",
    "                #checks if the GOAL is reached. Sets the done to True to avoid KeyError (a higher state can be reached\n",
    "                # but we don't want to reach it, because we don't have in in our state_space.)\n",
    "                if get_max(observation_)==GOAL:\n",
    "                    game_won = True\n",
    "                \n",
    "                if get_max(observation_)>max_value:\n",
    "                    max_value = get_max(observation_)\n",
    "                    \n",
    "                observation=observation_\n",
    "            \n",
    "            \n",
    "            if game_won == True:\n",
    "                won+= 1\n",
    "\n",
    "            if EPSILON > 0.0002:\n",
    "                EPSILON -= 2/(numGames)  \n",
    "            else:\n",
    "                EPSILON = 0.0002\n",
    "            totalRewards.append(epRewards)\n",
    "            max_total += get_max(observation)\n",
    "            \n",
    "            if (i+1)%(BATCH_SIZE) == 0:\n",
    "                new = won/(BATCH_SIZE)\n",
    "                num_won.append(new)\n",
    "                max_values.append(max_value)\n",
    "                average = max_total/BATCH_SIZE\n",
    "                avg_values.append(average)\n",
    "                won = 0\n",
    "                max_value = 0\n",
    "                max_total = 0\n",
    "                print(\"Episode: \" + str(i+1))\n",
    "    \n",
    "\n",
    "\n",
    "x = [j for j in range(1,101)]\n",
    "    import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "plotLearning(x,num_won,'Batch','Won games in percentage', 'Win-Statistic')\n",
    "# get coeffs of linear fit\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,num_won)\n",
    "\n",
    "# use line_kws to set line label for legend\n",
    "ax = sns.regplot(x=x, y=num_won, color='b', \n",
    " line_kws={'label':\"y={0:.7f}x+{1:.7f}\".format(slope,intercept)})\n",
    "\n",
    "# plot legend\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plotLearning(x,max_values,'Batch','Max_values', 'Max-Statistic')\n",
    "# get coeffs of linear fit\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,max_values)\n",
    "\n",
    "# use line_kws to set line label for legend\n",
    "ax = sns.regplot(x=x, y=max_values, color='b', \n",
    " line_kws={'label':\"y={0:.7f}x+{1:.7f}\".format(slope,intercept)})\n",
    "\n",
    "# plot legend\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plotLearning(x,avg_values,'Batch','Avg_values', 'Average-Max-Statistic')\n",
    "# get coeffs of linear fit\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,avg_values)\n",
    "\n",
    "# use line_kws to set line label for legend\n",
    "ax = sns.regplot(x=x, y=avg_values, color='b', \n",
    " line_kws={'label':\"y={0:.7f}x+{1:.7f}\".format(slope,intercept)})\n",
    "\n",
    "# plot legend\n",
    "ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "            "
   ]
  }
 ]
}